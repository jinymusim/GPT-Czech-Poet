#!/bin/bash

# TEST MODEL

#qsub -N TestModelE2E2 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=2,  EPOCHSPOET=2,  TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=base,  MODEL=./Test-Model-e2e2, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

# EPOCH 4, EPOCH 8 Effective batch 64, 48

#qsub -N CZBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=base,  MODEL=./CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
#qsub -N CZBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=all,  MODEL=./CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar' shell_scripts/all_model_train_helper.sh 
#qsub -N CZUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
#qsub -N CZSyllableBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZProcessedBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh
#qsub -N CZProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N ALTBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=spital/gpt2-small-czech-cs,  MODELTYPE=base,  MODEL=./ALT-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=spital/gpt2-small-czech-cs,  MODELTYPE=all,  MODEL=./ALT-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ALTUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=spital/gpt2-small-czech-cs' shell_scripts/all_model_train_helper.sh  
#qsub -N ALTUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ALTSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTSyllableBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ALTProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTProcessedBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=gpt2,  MODELTYPE=base,  MODEL=./EN-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=gpt2,  MODELTYPE=all,  MODEL=./EN-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=gpt2' shell_scripts/all_model_train_helper.sh
#qsub -N ENUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENSyllableBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENProcessedBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=distilgpt2,  MODELTYPE=base,  MODEL=./ENALT-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=distilgpt2,  MODELTYPE=all,  MODEL=./ENALT-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=distilgpt2' shell_scripts/all_model_train_helper.sh
#qsub -N ENALTUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENALTSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTSyllableBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTProcessedBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 


# RNN Models

#qsub -N RNNBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=RWKV/rwkv-4-169m-pile,  MODELTYPE=base,  MODEL=./RNN-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=RWKV/rwkv-4-169m-pile,  MODELTYPE=all,  MODEL=./RNN-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile' shell_scripts/all_model_train_helper.sh 
#qsub -N RNNUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNSyllableBPENormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNProcessedBPENormalTextGPTAllTasksE4E8 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh


# EPOCH 4, EPOCH 16

#qsub -N CZBaseTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=base,  MODEL=./CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
#qsub -N CZBaseTokenizerNormalTextGPTAllTasksE0E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=0,  EPOCHSPOET=16, TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=all,  MODEL=./CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e0e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZUnicodeTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=lchaloupsky/czech-gpt2-oscar' shell_scripts/all_model_train_helper.sh 
#qsub -N CZUnicodeTokenizerNormalTextGPTAllTasksE0E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=0,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e0e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZSyllableBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
#qsub -N CZSyllableBPENormalTextGPTAllTasksE0E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=0,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e0e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 

#qsub -N CZProcessedBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
#qsub -N CZProcessedBPENormalTextGPTAllTasksE0E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=0,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e0e16, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh

#qsub -N ALTBaseTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=spital/gpt2-small-czech-cs,  MODELTYPE=base,  MODEL=./ALT-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTBaseTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16, TOKENIZER=spital/gpt2-small-czech-cs,  MODELTYPE=all,  MODEL=./ALT-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ALTUnicodeTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=spital/gpt2-small-czech-cs' shell_scripts/all_model_train_helper.sh  
#qsub -N ALTUnicodeTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ALTSyllableBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTSyllableBPENormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ALTProcessedBPENormalTextGPTBaseTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ALT-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh 
#qsub -N ALTProcessedBPENormalTextGPTAllTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ALT-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=spital/gpt2-small-czech-cs'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENBaseTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=gpt2,  MODELTYPE=base,  MODEL=./EN-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENBaseTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16, TOKENIZER=gpt2,  MODELTYPE=all,  MODEL=./EN-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENUnicodeTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=gpt2' shell_scripts/all_model_train_helper.sh
#qsub -N ENUnicodeTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENSyllableBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENSyllableBPENormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENProcessedBPENormalTextGPTBaseTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./EN-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENProcessedBPENormalTextGPTAllTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./EN-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=gpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTBaseTokenizerNormalTextGPTBaseTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=distilgpt2,  MODELTYPE=base,  MODEL=./ENALT-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTBaseTokenizerNormalTextGPTAllTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16, TOKENIZER=distilgpt2,  MODELTYPE=all,  MODEL=./ENALT-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTUnicodeTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=distilgpt2' shell_scripts/all_model_train_helper.sh
#qsub -N ENALTUnicodeTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh
#
#qsub -N ENALTSyllableBPENormalTextGPTBaseTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTSyllableBPENormalTextGPTAllTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N ENALTProcessedBPENormalTextGPTBaseTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./ENALT-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 
#qsub -N ENALTProcessedBPENormalTextGPTAllTasksE4E16 -q gpu -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=24:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./ENALT-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=distilgpt2'  shell_scripts/all_model_train_helper.sh 

# RNN Models

#qsub -N RNNBaseTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=RWKV/rwkv-4-169m-pile,  MODELTYPE=base,  MODEL=./RNN-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNBaseTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16, TOKENIZER=RWKV/rwkv-4-169m-pile,  MODELTYPE=all,  MODEL=./RNN-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNUnicodeTokenizerNormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile' shell_scripts/all_model_train_helper.sh 
#qsub -N RNNUnicodeTokenizerNormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNSyllableBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNSyllableBPENormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 

#qsub -N RNNProcessedBPENormalTextGPTBaseTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./RNN-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh 
#qsub -N RNNProcessedBPENormalTextGPTAllTasksE4E16 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=16,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./RNN-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e16, HFMODEL=RWKV/rwkv-4-169m-pile'  shell_scripts/all_model_train_helper.sh

# Distil Models

#qsub -N DistilBaseE16E32 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=16,  EPOCHSPOET=32,  TOKENIZER=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16_LM,  MODELTYPE=distil,  MODEL=./Distil-Base-gpt-cz-poetry-e16e32, HFMODEL=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16_LM'  shell_scripts/all_model_train_helper.sh
#qsub -N DistilUnicodeE16E32 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=16,  EPOCHSPOET=32,  TOKENIZER=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16_LM,  MODELTYPE=distil,  MODEL=./Distil-Unicode-gpt-cz-poetry-e16e32, HFMODEL=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e16_LM'  shell_scripts/all_model_train_helper.sh 
#qsub -N DistilSyllableE16E32 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=16,  EPOCHSPOET=32,  TOKENIZER=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16_LM,  MODELTYPE=distil,  MODEL=./Distil-Syllable-gpt-cz-poetry-e16e32, HFMODEL=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e16_LM'  shell_scripts/all_model_train_helper.sh 
#qsub -N DistilProcessedE16E32 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=16,  EPOCHSPOET=32,  TOKENIZER=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16_LM,  MODELTYPE=distil,  MODEL=./Distil-Processed-gpt-cz-poetry-e16e32, HFMODEL=/storage/brno2/home/chudobm/tf_shorts/Tensorflow-Shorts/PoetGen/CZ-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e16_LM'  shell_scripts/all_model_train_helper.sh


# LARGE MODELS

#qsub -N LargeBaseTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=stabilityai/StableBeluga-7B,  MODELTYPE=base,  MODEL=./Large-Base-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#qsub -N LargeBaseTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8, TOKENIZER=stabilityai/StableBeluga-7B,  MODELTYPE=all,  MODEL=./Large-Base-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N LargeUnicodeTokenizerNormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=base,  MODEL=./Large-Unicode-Tokenizer-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=stabilityai/StableBeluga-7B' shell_scripts/all_model_train_helper.sh 
#qsub -N LargeUnicodeTokenizerNormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=all,  MODEL=./Large-Unicode-Tokenizer-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N LargeSyllableBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./Large-New-Syllable-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#qsub -N LargeSyllableBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./Large-New-Syllable-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#
#qsub -N LargeProcessedBPENormalTextGPTBaseTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=base,  MODEL=./Large-New-Processed-BPE-NormalText-gpt-cz-poetry-base-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh 
#qsub -N LargeProcessedBPENormalTextGPTAllTasksE4E8 -q gpu -l select=1:ncpus=4:ngpus=2:mem=80gb:gpu_mem=30gb:scratch_local=64gb -l walltime=48:00:00 -v 'EPOCHSLM=4,  EPOCHSPOET=8,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=all,  MODEL=./Large-New-Processed-BPE-NormalText-gpt-cz-poetry-all-e4e8, HFMODEL=stabilityai/StableBeluga-7B'  shell_scripts/all_model_train_helper.sh

# CUSTOM EMBED SIZE

qsub -N EmbedBaseE128E256 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=128,  EPOCHSPOET=256,  TOKENIZER=lchaloupsky/czech-gpt2-oscar,  MODELTYPE=small,  MODEL=./Embed-Base-gpt-cz-poetry-e128e256, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh
qsub -N EmbedUnicodeE128E256 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=128,  EPOCHSPOET=256,  TOKENIZER=./utils/tokenizers/Unicode/unicode_tokenizer.json,  MODELTYPE=small,  MODEL=./Embed-Unicode-gpt-cz-poetry-e128e256, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
qsub -N EmbedSyllableE128E256 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=128,  EPOCHSPOET=256,  TOKENIZER=./utils/tokenizers/BPE/new_syllabs_processed_tokenizer.json,  MODELTYPE=small,  MODEL=./Embed-Syllable-gpt-cz-poetry-e128e256, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh 
qsub -N EmbedProcessedE128E256 -q gpu_dgx -l select=1:ncpus=4:ngpus=2:mem=40gb:gpu_mem=30gb:scratch_local=64gb -l walltime=200:00:00 -v 'EPOCHSLM=128,  EPOCHSPOET=256,  TOKENIZER=./utils/tokenizers/BPE/new_processed_tokenizer.json,  MODELTYPE=small,  MODEL=./Embed-Processed-gpt-cz-poetry-e128e256, HFMODEL=lchaloupsky/czech-gpt2-oscar'  shell_scripts/all_model_train_helper.sh
